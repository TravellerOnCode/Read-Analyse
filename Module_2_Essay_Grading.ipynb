{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Module_2_Essay_Grading.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmrv2c--6Vsi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "outputId": "9afb8747-e16e-4351-fb86-be54b51f62e4"
      },
      "source": [
        "#Required Libraries\n",
        "import matplotlib.pyplot as plt \n",
        "import pandas as pd\n",
        "import io\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing import sequence,text\n",
        "\n",
        "\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten\n",
        "from keras.models import Sequential, load_model, model_from_config\n",
        "import keras.backend as K\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "# Restart runtime using 'Runtime' -> 'Restart runtime...'\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUiEDMg98N9A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d79f3749-2e55-45a1-95d2-c58a3ec3979c"
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "texBiya26r-q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "ef05e7f7-ed00-4376-9c2f-71fb75051112"
      },
      "source": [
        "!gsutil cp gs://cloud-training-demos/courses/machine_learning/deepdive/09_sequence/text_classification/glove.6B.200d.txt glove.6B.200d.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/09_sequence/text_classification/glove.6B.200d.txt...\n",
            "/ [1 files][661.3 MiB/661.3 MiB]   24.4 MiB/s                                   \n",
            "Operation completed over 1 objects/661.3 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22jGTVtf6sCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA8i5_IT-9w6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load the data and store in a data frame\n",
        "def load_data():\n",
        "  df = pd.read_csv(r'essays_and_scores.csv',encoding='latin-1')\n",
        "  data = df[['essay_id','essay_set','essay','rater1_domain1','rater1_domain1','domain1_score']].copy()\n",
        "  data = data.dropna() #drop all NaN values\n",
        "  #print(data)\n",
        "  #check details of the data\n",
        "  print(data['essay'].apply(len).describe())\n",
        "  return data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0D9ruQ0HtQHR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualize_data(data):\n",
        "  x = [len(w.split()) for w in data['essay']]  #store no of words of each essay in a list\n",
        "\n",
        "  n, bins, patches = plt.hist(x=x, bins='auto', color='#0504aa',alpha=0.7, rwidth=0.85)  #histogram plot\n",
        "  \n",
        "  #plt.grid(axis='y', alpha=0.75)\n",
        "  plt.xlabel('No. of words')\n",
        "  plt.ylabel('Frequency')\n",
        "  plt.title('essay length vs freq')\n",
        "  maxfreq = n.max()\n",
        "  \n",
        "  # Set a clean upper y-axis limit.\n",
        "  plt.ylim(ymax=np.ceil(maxfreq / 10) * 10 if maxfreq % 10 else maxfreq + 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE-Y3SgDAzYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_data(data):\n",
        "\n",
        "  #remove all punctuations\n",
        "  data_ = [\n",
        "      [(word.replace(\",\", \"\")\n",
        "            .replace(\".\", \"\")\n",
        "            .replace(\"(\", \"\")\n",
        "            .replace(\")\", \"\")\n",
        "            .replace(\"@\", \"\")\n",
        "            .replace(\"?\", \"\")\n",
        "           .replace(\"!\", \"\")\n",
        "            .replace(\":\", \"\"))\n",
        "      for word in row.lower().split()]\n",
        "      for row in data['essay']]\n",
        "\n",
        "  #restore words to sentences\n",
        "\n",
        "  str1=\"\"\n",
        "  essay_d=[]\n",
        "  for d in data_:\n",
        "    #print(d)\n",
        "    for i in d:\n",
        "      str1 = str1 + i + \" \"\n",
        "    essay_d.append(str1)\n",
        "    str1=\"\"\n",
        "\n",
        "  #score = [data['rater1_domain1'] + data['rater1_domain1'] ] / data['domain1_score'] * 2 \n",
        "  #score = score * 100\n",
        "  new_data = pd.DataFrame(list(zip(essay_d,data['domain1_score'])),columns = ['Essay','Score'])\n",
        "\n",
        "  return (new_data)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwZ_KeKpBsDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_test_train(new_data):\n",
        "  #shuffle the dataset before splitting\n",
        "  new_data1 = shuffle(new_data)\n",
        "\n",
        "  train = new_data1.sample(frac=0.8)\n",
        "  new_data1.drop(train.index, axis=0, inplace=True)\n",
        "  valid = new_data1.sample(frac=0.5)\n",
        "  new_data1.drop(valid.index, axis=0, inplace=True)\n",
        "  test = new_data1\n",
        "  print(train.shape , test.shape , valid.shape )\n",
        "\n",
        "  def return_data(df):\n",
        "    return list(df['Essay']), np.array(df['Score'])\n",
        "\n",
        "\n",
        "  # Apply it to the three splits\n",
        "  train_essay, train_score = return_data(train)\n",
        "  valid_essay, valid_score = return_data(valid)\n",
        "  test_essay, test_score = return_data(test)\n",
        "  print(train_essay[0], train_score[0])\n",
        "  \n",
        "  #return a tuple of values \n",
        "  return (train_essay,train_score,valid_essay,valid_score,test_essay,test_score)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SS7s8joJMiLT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_data(train_essay,valid_esssay,test_essay):\n",
        "  \n",
        "  # Create a vocabulary from training corpus\n",
        "  #tokenizer = text.Tokenizer(num_words=TOP_K)\n",
        "  #tokenizer.fit_on_texts(train_essay)\n",
        "\n",
        "  #word_index=tokenizer.word_index\n",
        "  #print(word_index)\n",
        "\n",
        "  # Preprocess the train, validation and test sets\n",
        "  # Tokenize and pad sentences\n",
        "  preproc_train = tokenizer.texts_to_sequences(train_essay)\n",
        "  preproc_train = sequence.pad_sequences(preproc_train, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "  preproc_valid = tokenizer.texts_to_sequences(valid_essay)\n",
        "  preproc_valid = sequence.pad_sequences(preproc_valid, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "  preproc_test = tokenizer.texts_to_sequences(test_essay)\n",
        "  preproc_test = sequence.pad_sequences(preproc_test, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "  #return a tuple of values\n",
        "  return (preproc_train,preproc_valid,preproc_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGhE7DfMSm_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_embedding_matrix(word_index, embedding_path, embedding_dim):\n",
        "  embedding_matrix_all = {}\n",
        "  with open(embedding_path) as f:\n",
        "    for line in f:  # Every line contains word followed by the vector value\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embedding_matrix_all[word] = coefs\n",
        "\n",
        "        \n",
        "  # Prepare embedding matrix with just the words in our word_index dictionary\n",
        "  num_words = min(len(word_index) + 1, TOP_K)\n",
        "  embedding_matrix = np.zeros((num_words, embedding_dim))\n",
        "  for word, i in word_index.items():\n",
        "    if i >= TOP_K:\n",
        "        continue\n",
        "    embedding_vector = embedding_matrix_all.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "  \n",
        "  return embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "id4A8MAaD-92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "  # Create model instance\n",
        "  model = Sequential()\n",
        "  num_features = min(len(word_index) + 1, TOP_K)\n",
        "  # Add embedding layer - GloVe embeddings\n",
        "  model.add(Embedding(input_dim=num_features,\n",
        "                output_dim=embedding_dim,\n",
        "                input_length=MAX_SEQUENCE_LENGTH,\n",
        "                weights=[get_embedding_matrix(word_index, \n",
        "                                embedding_path, embedding_dim)],\n",
        "                trainable=True))\n",
        "\n",
        "\n",
        "\n",
        "  #Add more layers\n",
        "\n",
        "  model.add(LSTM(200, dropout=0.4, recurrent_dropout=0.4, input_shape=[1, 200], return_sequences=True))\n",
        "  model.add(LSTM(64, recurrent_dropout=0.4))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(1, activation='relu'))\n",
        "\n",
        "  model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
        "  model.summary()\n",
        "\n",
        "  return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAcxKXjJ6sGf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-lkhW_-c4nf",
        "colab_type": "code",
        "outputId": "03a8e2d7-420c-4316-cd7d-b2ba940f0a03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        }
      },
      "source": [
        "#Run the code \n",
        "\n",
        "data = load_data()\n",
        "visualize_data(data)\n",
        "new_data = clean_data(data)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "count    12977.000000\n",
            "mean      1215.871234\n",
            "std        958.321377\n",
            "min          8.000000\n",
            "25%        527.000000\n",
            "50%        900.000000\n",
            "75%       1670.000000\n",
            "max       6098.000000\n",
            "Name: essay, dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwJoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmnZDmF9GLKs",
        "colab_type": "code",
        "outputId": "1c761330-0c3c-4eb2-e075-e55c2a9525b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "\n",
        "train_essay,train_score,valid_essay,valid_score,test_essay,test_score = generate_test_train(new_data)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10382, 2) (1297, 2) (1298, 2)\n",
            "the features of the setting affect the cyclist by the mood the cyclist and what happens as he journeys in the desert to a town for example his mood changes when the old man asks him for a map and his attitude changes by cautiousness of the new of the new road he went on then terror when he thought he was gonna die ò i was gonna die and the birds would pick me cleanó then to pride when the old man asks for a map and the author says òi own a very good mapó but as he journeys to yosemite the setting changes when he goes to a desert type of place then goes a bait shop to rest then probably on his merry way to his destination  2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4117: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kXXkhhWjmMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Global Variables\n",
        "# Maximum vocabulary size used for tokenization\n",
        "TOP_K = 80000 \n",
        "# Sentences will be truncated/padded to this length\n",
        "MAX_SEQUENCE_LENGTH = 800"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eUNMU0Poo_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Create a vocabulary from training corpus\n",
        "tokenizer = text.Tokenizer(num_words=TOP_K)\n",
        "tokenizer.fit_on_texts(train_essay)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACwVKm3BCpul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preproc_train,preproc_valid,preproc_test = preprocess_data(train_essay,valid_essay,test_essay)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWbwOoBgjp6U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specify the hyperparameters\n",
        "filters=64\n",
        "dropout_rate=0.2\n",
        "embedding_dim=200\n",
        "kernel_size=3\n",
        "pool_size=3\n",
        "word_index=tokenizer.word_index    #initialized in preprocess func()\n",
        "embedding_path = 'glove.6B.200d.txt'\n",
        "embedding_dim=200   #the output dimension from the embedding layer to be fed to the next layer "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTXFeKgVSI8U",
        "colab_type": "code",
        "outputId": "c556a725-8140-409c-c3ca-ae7b799df4ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(len(preproc_train[0]))\n",
        "print(len(preproc_train[10]))\n",
        "\n",
        "print(len(preproc_train))\n",
        "print(len(preproc_test))\n",
        "print(len(preproc_valid))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "800\n",
            "800\n",
            "10382\n",
            "1297\n",
            "1298\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxHp11b4ZKeS",
        "colab_type": "code",
        "outputId": "29b4c431-82cb-4af4-ddb7-4bc351230fb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "model = build_model()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 800, 200)          7925600   \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 800, 200)          320800    \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 64)                67840     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 8,314,305\n",
            "Trainable params: 8,314,305\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Lx4BAdKSQg4",
        "colab_type": "code",
        "outputId": "0febc3cf-028f-436e-9cc8-a3442a9cbdc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "H = model.fit(preproc_train,\n",
        "         train_score,\n",
        "         validation_data=(preproc_valid, valid_score),\n",
        "         batch_size=128,\n",
        "         epochs=10,\n",
        "         verbose=1)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10382 samples, validate on 1298 samples\n",
            "Epoch 1/10\n",
            "10382/10382 [==============================] - 281s 27ms/step - loss: 16.7883 - mean_absolute_error: 2.1983 - val_loss: 9.0038 - val_mean_absolute_error: 1.6056\n",
            "Epoch 2/10\n",
            "10382/10382 [==============================] - 279s 27ms/step - loss: 12.5149 - mean_absolute_error: 1.9258 - val_loss: 7.3793 - val_mean_absolute_error: 1.4808\n",
            "Epoch 3/10\n",
            "10382/10382 [==============================] - 281s 27ms/step - loss: 9.3214 - mean_absolute_error: 1.7130 - val_loss: 4.3892 - val_mean_absolute_error: 1.2476\n",
            "Epoch 4/10\n",
            "10382/10382 [==============================] - 280s 27ms/step - loss: 7.1752 - mean_absolute_error: 1.5314 - val_loss: 4.5606 - val_mean_absolute_error: 1.3612\n",
            "Epoch 5/10\n",
            "10382/10382 [==============================] - 281s 27ms/step - loss: 6.6359 - mean_absolute_error: 1.4505 - val_loss: 4.2507 - val_mean_absolute_error: 1.2100\n",
            "Epoch 6/10\n",
            "10382/10382 [==============================] - 279s 27ms/step - loss: 6.1662 - mean_absolute_error: 1.3772 - val_loss: 3.9659 - val_mean_absolute_error: 1.2111\n",
            "Epoch 7/10\n",
            "10382/10382 [==============================] - 283s 27ms/step - loss: 5.6793 - mean_absolute_error: 1.3398 - val_loss: 3.7528 - val_mean_absolute_error: 1.1330\n",
            "Epoch 8/10\n",
            "10382/10382 [==============================] - 279s 27ms/step - loss: 5.3496 - mean_absolute_error: 1.2810 - val_loss: 3.5097 - val_mean_absolute_error: 1.0747\n",
            "Epoch 9/10\n",
            "10382/10382 [==============================] - 279s 27ms/step - loss: 5.4679 - mean_absolute_error: 1.2676 - val_loss: 4.3179 - val_mean_absolute_error: 1.2547\n",
            "Epoch 10/10\n",
            "10382/10382 [==============================] - 281s 27ms/step - loss: 4.9260 - mean_absolute_error: 1.2188 - val_loss: 3.0696 - val_mean_absolute_error: 1.0087\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_Un7bDLHvib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to be improved by increasing epochs and K-Fold Method"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szwkpEh2ZKbt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(preproc_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c_T3UvUIcbx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "c9a150a9-5462-4444-a24b-7f7273a59602"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.7193851],\n",
              "       [2.7752569],\n",
              "       [2.2101326],\n",
              "       ...,\n",
              "       [1.4913223],\n",
              "       [8.169723 ],\n",
              "       [1.9660587]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIOWxFI4I87h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d2ea22a7-7101-4433-9e7e-04f0736c3c9f"
      },
      "source": [
        "test_score.shape , y_pred.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1297,), (1297, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfHtBSWCZKXL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2993af4a-8e5b-457e-ffb2-bd5e04bea25c"
      },
      "source": [
        "result = cohen_kappa_score(test_score,np.around(y_pred),weights='quadratic')\n",
        "print(\"Kappa Score {}\".format(result))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Kappa Score 0.8760043562142501\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1YOcmMG6sJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = cohen_kappa_score(test_score,np.around(y_pred),weights='quadratic')\n",
        "print(\"Kappa Score {} : Epochs = 5 : Fold = 2\".format(result))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVs1Tz4v6sLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjRsQaSX6sOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNjHnZQL6sSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFO2ep5k6r8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}